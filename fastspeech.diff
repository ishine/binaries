diff --git a/synthesis.py b/synthesis.py
index dc5ce95..855c7d4 100644
--- a/synthesis.py
+++ b/synthesis.py
@@ -13,7 +13,10 @@ import utils
 import Audio
 import glow
 import waveglow
+import time
 
+start = 0
+end = 0
 device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
 
 
@@ -52,23 +55,38 @@ if __name__ == "__main__":
     num = 112000
     alpha = 1.0
     model = get_FastSpeech(num)
-    words = "Letâ€™s go out to the airport. The plane landed ten minutes ago."
-
+    start = time.time()
+    #words = "Today, I installed the software update from Ubuntu. Then on reboot, I never got to login screen. Something kept flashing on screen, but was too fast to see what it was saying."
+    words = "BBC News is a news aggregator and app developed by Google. It presents a continuous, customizable flow of articles organized from thousands of publishers and magazines."
+    #words = "take me to california"
     mel, mel_postnet, mel_torch, mel_postnet_torch = synthesis(
         model, words, alpha=alpha)
 
     if not os.path.exists("results"):
         os.mkdir("results")
-    Audio.tools.inv_mel_spec(mel_postnet, os.path.join(
-        "results", words + "_" + str(num) + "_griffin_lim.wav"))
-
-    wave_glow = utils.get_WaveGlow()
-    waveglow.inference.inference(mel_postnet_torch, wave_glow, os.path.join(
-        "results", words + "_" + str(num) + "_waveglow.wav"))
-
-    tacotron2 = utils.get_Tacotron2()
-    mel_tac2, _, _ = utils.load_data_from_tacotron2(words, tacotron2)
-    waveglow.inference.inference(torch.stack([torch.from_numpy(
-        mel_tac2).to(device)]), wave_glow, os.path.join("results", "tacotron2.wav"))
-
-    utils.plot_data([mel.numpy(), mel_postnet.numpy(), mel_tac2])
+    #Audio.tools.inv_mel_spec(mel_postnet, os.path.join(
+    # "results", words + "_" + str(num) + "_griffin_lim.wav"))
+
+    end = time.time()
+    print("MEL Calculation:")
+    print(end-start)
+     
+
+    start = time.time()
+    #wave_glow = utils.get_WaveGlow()
+    #IMPOPRTANT:uncomment unsqueeze in inference.py in Squeueze.if you are not squeezing here
+    #melspec = torch.squeeze(mel_postnet_torch, 0) 
+    torch.save(mel_postnet_torch, "/tmp/test.pt")
+
+    #waveglow.inference.inference(mel_postnet_torch, wave_glow, os.path.join(
+    #    "results", words + "_" + str(num) + "_waveglow.wav"))
+    #end = time.time()
+    #print("Waveglow Vocoder")
+    #print(end-start)
+
+  
+    #tacotron2 = utils.get_Tacotron2()
+    #mel_tac2, _, _ = utils.load_data_from_tacotron2(words, tacotron2)
+    #waveglow.inference.inference(torch.stack([torch.from_numpy(
+    #    mel_tac2).to(device)]), wave_glow, os.path.join("results", "tacotron2.wav"))
+
+    #utils.plot_data([mel.numpy(), mel_postnet.numpy(), mel_tac2])
